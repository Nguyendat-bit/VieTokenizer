# VieTokenizer
This is a new package that supports Vietnamese word segmentation based on deep learning methods. The model architecture we use is a simple bi-lstm network trained on a pre-labeled dataset. For example, the training set: "TÃ´i tÃªn lÃ  Nguyá»…n Tiáº¿n Äáº¡t" and the test set: "TÃ´i tÃªn lÃ  Nguyá»…n_Tiáº¿n_Äáº¡t". The model will predict if serial word is 1 and non-serial is 0, for example, "TÃ´i tÃªn lÃ  Nguyá»…n Tiáº¿n Äáº¡t" will be equivalent to a sequence of numbers with both zero and one being [0, 0, 0, 0, 1, 1]. 

## Installation ğŸ‰
- This repository is tested on python 3.7+ and Tensorflow 2.8+
- VieTokenizer can be installed using pip as follows:
```
pip install vietokenizer ğŸ°
```
- VieTokenizer can also be installed from source with the following commands: 
```
git clone https://github.com/Nguyendat-bit/VieTokenizer
cd VieTokenizer
pip install -e . 
```
## Usage ğŸ”¥
```python
>>> import vietokenizer
>>> tokenizer= vietokenizer.vntokenizer()
>>> tokenizer('TÃ´i tÃªn lÃ  Nguyá»…n Tiáº¿n Äáº¡t, hiá»‡n lÃ  sinh viÃªn Äáº¡i há»c CN GTVT táº¡i HÃ  Ná»™i.')
'TÃ´i tÃªn lÃ  Nguyá»…n_Tiáº¿n_Äáº¡t , hiá»‡n lÃ  sinh_viÃªn Äáº¡i_há»c CN GTVT táº¡i HÃ _Ná»™i .'
>>> tokenizer('Kim loáº¡i náº·ng thÆ°á»ng Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a lÃ  kim loáº¡i cÃ³ khá»‘i lÆ°á»£ng riÃªng, khá»‘i lÆ°á»£ng nguyÃªn tá»­ hoáº·c sá»‘ hiá»‡u nguyÃªn tá»­ lá»›n.')
'Kim_loáº¡i náº·ng thÆ°á»ng Ä‘Æ°á»£c Ä‘á»‹nh_nghÄ©a lÃ  kim_loáº¡i cÃ³ khá»‘i_lÆ°á»£ng riÃªng , khá»‘i_lÆ°á»£ng nguyÃªn_tá»­ hoáº·c sá»‘_hiá»‡u nguyÃªn_tá»­ lá»›n .'
```

## License
[Apache 2.0 License](https://github.com/Nguyendat-bit/VieTokenizer). <br>
Copyright &copy; 2022 [Nguyá»…n Tiáº¿n Äáº¡t](https://github.com/Nguyendat-bit). All rights reserved.
